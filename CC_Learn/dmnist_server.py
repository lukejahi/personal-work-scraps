# -*- coding: utf-8 -*-
"""dMNIST_server.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16juvlhtW-xdk7iOdjoKlzKxPaz2qtK1B
"""

#Code taken and modified from https://keras.io/examples/vision/mnist_convnet/ from user https://twitter.com/fchollet creator of Keras

import numpy as np
from tensorflow import keras
from tensorflow.keras import layers
from time import perf_counter

# Model / data parameters
num_classes = 10
input_shape = (28, 28, 1)

# the data, split between train and test sets
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

# Scale images to the [0, 1] range
x_tune = x_train.astype("float32") / 255
x_test = x_test.astype("float32") / 255
# Make sure images have shape (28, 28, 1)
x_tune = np.expand_dims(x_train, -1)
x_test = np.expand_dims(x_test, -1)

x_tune = x_tune[50000:]

print(x_test.shape[0], "test samples")
print(x_tune.shape[0], "tune samples")

y_tune = y_train[50000:]

# convert class vectors to binary class matrices
y_train = keras.utils.to_categorical(y_train, num_classes)
y_tune = keras.utils.to_categorical(y_tune, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

model = keras.Sequential(
    [
        keras.Input(shape=input_shape),
        layers.Conv2D(32, kernel_size=(3, 3), activation="relu"),
        layers.MaxPooling2D(pool_size=(2, 2)),
        layers.Conv2D(64, kernel_size=(3, 3), activation="relu"),
        layers.MaxPooling2D(pool_size=(2, 2)),
        layers.Flatten(),
        layers.Dropout(0.5),
        layers.Dense(num_classes, activation="softmax"),
    ]
)

model.summary()

model.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["categorical_accuracy"])

#server setup stuff
import socket
import time
import pickle

HEADERSIZE = 10

#Networking code modified from https://pythonprogramming.net/pickle-objects-sockets-tutorial-python-3/

def get_msg(connection,addrs):
  full_msg = b''
  new_msg = True
  in_progress = True;
  while in_progress:
      msg = connection.recv(1024)
      if new_msg:
          #print("new msg len:",msg[:HEADERSIZE])
          msglen = int(msg[:HEADERSIZE])
          new_msg = False

      #print(f"full message length: {msglen}")

      full_msg += msg

      print(len(full_msg))

      if len(full_msg)-HEADERSIZE == msglen:
          print("full msg recvd from ", addrs)
          #print(full_msg[HEADERSIZE:])
          #print(pickle.loads(full_msg[HEADERSIZE:]))
          return pickle.loads(full_msg[HEADERSIZE:])

def calculate_weighted_avg(weights_m,loss_m,epoch):
  weighted_total = np.zeros_like(weights_m[1])
  
  for weight in weights_m:
    weighted_total = np.add(weighted_total, weight)
    
  if epoch == 0:
    return weighted_total/(len(weights_m)-1) #ignore the empty global weights
  else:
    return weighted_total/len(weights_m)

HEADERSIZE = 10

EPOCHs = 3

s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
s.bind(("192.168.1.170", 4321))
s.listen(2)

connections = []
addresses = []
conn = 0;

print("Waiting on connections...")

while conn < 1:
  c, addr = s.accept()     # Establish connection with client.
  print("Connection Made...")
  connections.append(c)
  addresses.append(addr)
  conn = conn + 1

weights = [np.zeros_like(np.array(model.get_weights())),np.zeros_like(np.array(model.get_weights()))]
losses = [0.0,0.0]

# Start the stopwatch / counter 
t1_start = perf_counter() 



for x in range(EPOCHs):
  response = get_msg(connections[0],addresses[0])
  weights[0] = response[0];
  losses[0] = response[1];
  #response = get_msg(connections[1],addresses[1])
  #weights[1] = np.array(response[0]);
  #losses[1] = response[1];

  if x == 0:
      losses[1] = 0.0
  else:
      losses[1] = score[0]
  weights[1] = np.array(model.get_weights())
  new_weights = calculate_weighted_avg(weights,losses,x)
  model.set_weights(new_weights)
  score = model.evaluate(x_tune,y_tune)
  print("Tune loss:", score[0])
  print("Tune accuracy:", score[1])
  msg = pickle.dumps(np.array(model.get_weights()))
  msg = bytes(f"{len(msg):<{HEADERSIZE}}", 'utf-8')+msg
  connections[0].send(msg)
  print("Sync_Iteration:", x)


# Stop the stopwatch / counter 
t1_stop = perf_counter() 

connections[0].close()
s.close()

print("Elapsed time during the whole program in seconds:", 
                                        t1_stop-t1_start)

file1 = open("Epochruns_3.csv", "a")  # append mode 
file1.write(str(t1_stop-t1_start))
file1.write(",")
file1.close() 

# Start the stopwatch / counter 
t2_start = perf_counter() 

score = model.evaluate(x_test, y_test)
# Stop the stopwatch / counter 
t2_stop = perf_counter() 

print("Elapsed time during the whole program in seconds:", 
                                        t2_stop-t2_start)

file1 = open("Epochruns_3.csv", "a")  # append mode 
file1.write(str(t2_stop-t2_start))
file1.write(",")
file1.close() 

print("Test loss:", score[0])
print("Test accuracy:", score[1])

file1 = open("Epochruns_3.csv", "a")  # append mode 
file1.write(str(score[1]))
file1.write("\n")
file1.close() 